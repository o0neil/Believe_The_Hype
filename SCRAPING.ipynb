{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normal Imports\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.width', 500)\n",
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "# Additional Imports Needed\n",
    "from pyquery import PyQuery as pq\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Query the online database for the 'basic info'\n",
    "basicinfo=requests.get(\"http://www.irgcis.irri.org:81/grc/TK.exe$Query?DataSource=IRG&GBUSER_TK_PASS1_ORICOUNTRY.STATUS_ACC-OP=%3D&GBUSER_TK_PASS1_ORICOUNTRY.STATUS_ACC=&GBUSER_TK_PASS1_ORICOUNTRY.ACCNO-OP=%3E%3D&GBUSER_TK_PASS1_ORICOUNTRY.ACCNO=&GBUSER_TK_PASS1_ORICOUNTRY.ACCNO-OP=%3C%3D&GBUSER_TK_PASS1_ORICOUNTRY.ACCNO=&GBUSER_TK_PASS1_ORICOUNTRY.SPECIES_REID-OP=%3D&GBUSER_TK_PASS1_ORICOUNTRY.SPECIES_REID=&GBUSER_TK_PASS1_ORICOUNTRY.ALL_ACCNO_NAME-OP=ctn&GBUSER_TK_PASS1_ORICOUNTRY.ALL_ACCNO_NAME=&GBUSER_TK_PASS1_ORICOUNTRY.ORI_COUNTRY-OP=%3D&GBUSER_TK_PASS1_ORICOUNTRY.ORI_COUNTRY=&GBUSER_TK_PASS1_SSCOUNTRY.SS_COUNTRY-OP=%3D&GBUSER_TK_PASS1_SSCOUNTRY.SS_COUNTRY=&GBUSER_TK_PASS1_ORICOUNTRY.CULT_TYPE-OP=%3D&GBUSER_TK_PASS1_ORICOUNTRY.CULT_TYPE=&GBUSER_TK_MORPH1_2.MAT-OP=%3E%3D&GBUSER_TK_MORPH1_2.MAT=&GBUSER_TK_MORPH1_2.MAT-OP=%3C%3D&GBUSER_TK_MORPH1_2.MAT=&GBUSER_TK_MORPH1_2.GRLT-OP=%3E%3D&GBUSER_TK_MORPH1_2.GRLT=&GBUSER_TK_MORPH1_2.GRLT-OP=%3C%3D&GBUSER_TK_MORPH1_2.GRLT=&GBUSER_TK_MORPH1_2.GRWD-OP=%3E%3D&GBUSER_TK_MORPH1_2.GRWD=&GBUSER_TK_MORPH1_2.GRWD-OP=%3C%3D&GBUSER_TK_MORPH1_2.GRWD=&GBUSER_TK_MORPH1_2.VG-OP=%3D&GBUSER_TK_MORPH1_2.VG=&GBUSER_TK_MORPH1_2.ENDO-OP=%3D&GBUSER_TK_MORPH1_2.ENDO=&GBUSER_TK_MORPH1_2.SCCO_REV-OP=%3D&GBUSER_TK_MORPH1_2.SCCO_REV=&GBUSER_TK_EVAL.BL_DESCRIPTION-OP=ctn&GBUSER_TK_EVAL.BL_DESCRIPTION=&GBUSER_TK_EVAL.BB_DESCRIPTION-OP=ctn&GBUSER_TK_EVAL.BB_DESCRIPTION=&GBUSER_TK_EVAL.SHB_DESCRIPTION-OP=ctn&GBUSER_TK_EVAL.SHB_DESCRIPTION=&Output=%2FGRC%2FAccessionID.htm&Limit=-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean page text to find only the rows corresponding to be data on rice (poor HTML formatting)\n",
    "d_= pq(basicinfo.text)\n",
    "d_rows = pq(d_('tr')[4:])\n",
    "d_rows = pq(d_rows[:(len(d_rows)-1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Start by creating an empty list.\n",
    "ricestrains=[]\n",
    "fields=['strain_id', 'species_name', 'variety_name', 'previous_name', \n",
    "        'pedigree', 'collection_number', 'acc_id_seq_num', 'acc_id_seed_donor_number',\n",
    "        'source_country', 'donor_country', 'acc_date', 'status', 'cultural_type',\n",
    "        'special_traits', 'fao_in_trust', 'multilateral_system']\n",
    "\n",
    "# Iterate over the elements of d_rows. In this case \"r\" will\n",
    "# receive each value from \"d_rows\" in turn.\n",
    "for r in d_rows:\n",
    "    # Extract the \"td\" element from the current value of r.\n",
    "    d_td=pq(r)('td')\n",
    "    \n",
    "    strain_id =  int(pq(d_td[0]).text())\n",
    "    species_name = pq(d_td[1]).text()\n",
    "    variety_name = pq(d_td[2]).text()\n",
    "    previous_name = pq(d_td[3]).text()\n",
    "    pedigree = pq(d_td[4]).text()\n",
    "    collection_num = pq(d_td[5]).text()\n",
    "    acc_id_seq_num = pq(d_td[6]).text()\n",
    "    acc_id_seed_don_num = pq(d_td[7]).text()\n",
    "    source_country = pq(d_td[8]).text()\n",
    "    donor_country = pq(d_td[9]).text()\n",
    "    acc_date = pq(d_td[10]).text()\n",
    "    status = pq(d_td[11]).text()\n",
    "    cultural_type = pq(d_td[12]).text()\n",
    "    special_traits = pq(d_td[13]).text()\n",
    "    fao_in_trust = pq(d_td[14]).text()\n",
    "    multi_later_sys = pq(d_td[15]).text()\n",
    "    \n",
    "    a = [strain_id, species_name, variety_name, previous_name,\n",
    "         pedigree, collection_num, acc_id_seq_num, acc_id_seed_don_num,\n",
    "         source_country, donor_country, acc_date, status, cultural_type,\n",
    "         special_traits, fao_in_trust, multi_later_sys]\n",
    "    \n",
    "    ricedict = dict(zip(fields,a))\n",
    "    \n",
    "    ricestrains.append(ricedict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131112"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ricestrains)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tempdf=pd.DataFrame(ricestrains)\n",
    "#tempdf[:35]\n",
    "tempdf.to_pickle(\"firstpass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                <audio controls=\"controls\" autoplay=\"autoplay\">\n",
       "                    <source src=\"http://sfxcontent.s3.amazonaws.com/soundfx/EmergencyAlertSystemBeep.mp3\" type=\"audio/mpeg\" />\n",
       "                    Your browser does not support the audio element.\n",
       "                </audio>\n",
       "              "
      ],
      "text/plain": [
       "<IPython.lib.display.Audio object>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FUN SOUND BIT\n",
    "from IPython.display import Audio\n",
    "sound_file = 'http://sfxcontent.s3.amazonaws.com/soundfx/EmergencyAlertSystemBeep.mp3'\n",
    "Audio(url=sound_file, autoplay=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # We'll just reuse the request object that was previously created to create a BeautifulSoup element.\n",
    "# # The latter will be the equivalent of the \"d_\" object we created before.\n",
    "# soup = BeautifulSoup(take1.text, \"html.parser\")\n",
    "\n",
    "# # # In this line we are looking for a single \"table\" element with a class of wikitable;\n",
    "# # # and then looking for all the \"tr\" elements on that table (notice the find vs find_all calls).\n",
    "# # # Even though the syntax is very different from PyQuery, the end result is similar.\n",
    "# rows = soup.find(\"table\").find_all(\"tr\")\n",
    "\n",
    "# # # We then define an anonymous (lambda) function whose job it is to act on\n",
    "# # #each column's element in each row in the table. Lambda functions are very\n",
    "# # # handy for functional programming, and the one below should be easy to follow.\n",
    "# # # The function processes each field of the parameter r accordingly. It starts by\n",
    "# # # transforming the first column into an integer; it then proceeds to getting the text\n",
    "# # # from the second and third elements, and finally it gets the HTTP link of the third\n",
    "# # # element, and returns all that in a list (notice the surrounding brackets).\n",
    "# # # The function is then bound to the cleaner variable so it can be referenced later.\n",
    "# # cleaner = lambda r: [int(r[0].get_text()), r[1].get_text(), r[2].get_text(), r[2].find(\"a\").get(\"href\")]\n",
    "\n",
    "# # #lambda functions are also excellent for defining one line math functions.\n",
    "# # #e.g. radius = lambda x,y: np.sqrt(x*x + y*y)\n",
    "\n",
    "# # # Next we'll create a list of names that will be used as dictionary keys.\n",
    "# # fields = [\"ranking\", \"title\", \"band_singer\", \"url\"]\n",
    "\n",
    "# # # We now use the lambda function to process each \"td\" element on a given row.\n",
    "# # # the [... for ... in ...] construct is a list comprehension. They look weird at\n",
    "# # # first but are amazingly useful and worth spending some time to learn.\n",
    "# # # At a high level, thing of it as a one line \"for loop\" that aggregates the result\n",
    "# # # of each iteration into a list. So once this line finished running, we will have a list\n",
    "# # # of something.\n",
    "# # #\n",
    "# # # The dict function is another way to create a dictionary. One neat thing about it\n",
    "# # # is that it accepts a list of key/value pairs that will be used to create said dictionary.\n",
    "# # #\n",
    "# # # But where are these key/value pairs coming from in here? From the zip function!\n",
    "# # # The zip function will take multiple iterables (things that can be treated as a sequence)\n",
    "# # # and combine them. An example might make it clearer:\n",
    "# # #\n",
    "# # # zip([\"a\", \"b\", \"c\"], [1, 2, 3]) evaluates to [(\"a\", 1), (\"b\", 2), (\"c\", 3)]. It's like a zipper!!!\n",
    "# # #\n",
    "# # # Anyway, never mind the parenthesis around the pairs; they just show that the elements\n",
    "# # # are grouped into tuples, which you can think of as lists that are immutable (they can't grow or shrink).\n",
    "# # #\n",
    "# # # So to recap: the zip function creates a list of pairs; which the dict function then uses\n",
    "# # # to create a dictionary, using the first element of the pair as the key and the second as\n",
    "# # # the value; and finally, the list comprehension iterates over each row element, and puts\n",
    "# # # the result of each iteration on a list, which is then bound to the songs variable.\n",
    "# # songs = [dict(zip(fields, cleaner(row.find_all(\"td\")))) for row in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'band_singer': 'The Guess Who',\n",
       "  'ranking': 3,\n",
       "  'title': 'American Woman',\n",
       "  'url': '/wiki/The_Guess_Who'},\n",
       " {'band_singer': 'B.J. Thomas',\n",
       "  'ranking': 4,\n",
       "  'title': \"Raindrops Keep Fallin' on My Head\",\n",
       "  'url': '/wiki/B.J._Thomas'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
